{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import collections\n",
    "from typing import Dict, List\n",
    "import json\n",
    "sys.path.append('/home/ubuntu/MLData/work/Repos/NeuralIR/neural_IR')\n",
    "\n",
    "from utils.metrics import compute_MRR_metrics, compute_recall_at_k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/d/MLData/Repos/neural_IR/assets/msmarco/query_2_groundtruth_passage_small.json', 'r') as file:\n",
    "    query_2_top_pid_groundtruth = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/d/MLData/Repos/neural_IR/assets/msmarco/query_2_top_1000_passage_BM25.json', 'r') as file:\n",
    "    query_2_top_pid_candiates_BM25 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "6980\n"
     ]
    }
   ],
   "source": [
    "print(type(query_2_top_pid_groundtruth))\n",
    "print(type(next(iter(query_2_top_pid_groundtruth))))\n",
    "print(len(query_2_top_pid_groundtruth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Ranking result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6836\n"
     ]
    }
   ],
   "source": [
    "result_file = \"/mnt/d/MLData/Repos/neural_IR/experiments/msmarco_psg_ranking/evaluation/ranking.tsv\"\n",
    "\n",
    "query_2_pid_raw = collections.defaultdict(list)\n",
    "with open(result_file) as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split()\n",
    "        query_2_pid_raw[parts[0]].append((parts[2], parts[1]))\n",
    "\n",
    "query_2_top_pid_candiates = {}\n",
    "for key in query_2_pid_raw:\n",
    "    query_2_pid_raw[key].sort()\n",
    "    query_2_top_pid_candiates[key] = [e[1] for e in query_2_pid_raw[key]]\n",
    "\n",
    "print(len(query_2_top_pid_candiates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "num_pids = [len(l) for l in query_2_top_pid_candiates.values()]\n",
    "print(sum(num_pids) // len(num_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['188714', '1082792', '995526', '199776', '660957', '820267', '837202', '130825', '408149', '345453', '1019649', '1099065', '542431', '1084910', '959083', '816483', '995825', '559771', '1091246', '167436', '899212', '1101211', '1047854', '991832', '426442', '1093443', '779475', '1040038', '706950', '185299', '574730', '1085008', '1011382', '1062784', '1090701', '973917', '999517', '596716', '289276', '990995', '609628', '988787', '996805', '1025483', '998493', '358455', '435412', '1090730', '348594', '218000', '760512', '665972', '1006751', '596130', '988119', '942221', '1001108', '23285', '1002148', '1097438', '727707', '791140', '259417', '913568', '198246', '370734', '1056265', '432874', '1089312', '141694', '1093781', '1009183', '762059', '931147', '1027650', '170770', '1027817', '939866', '1031456', '480064', '1098608', '234114', '27743', '1089868', '404051', '1075636', '684459', '591940', '313940', '1043545', '510893', '250367', '1101531', '920753', '1054339', '1093552', '1045203', '425688', '995280', '412340', '970605'])\n",
      "['7067032']\n"
     ]
    }
   ],
   "source": [
    "print(query_2_top_pid_candiates.keys())\n",
    "print(next(iter(query_2_top_pid_groundtruth.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall_at_k(query_2_top_pid_groundtruth: Dict[int, List[int]], query_2_top_pid_candiates: Dict[int, List[int]], retrieval_num):\n",
    "    recall_at_k = [len(set.intersection(set(query_2_top_pid_groundtruth[qid]), set(query_2_top_pid_candiates[qid][:retrieval_num]))) / max(1.0, len(query_2_top_pid_groundtruth[qid]))\n",
    "                    for qid in query_2_top_pid_candiates]\n",
    "    recall_at_k = sum(recall_at_k) / len(query_2_top_pid_candiates)\n",
    "    recall_at_k = round(recall_at_k, 7)\n",
    "    print(f\"Recall @ {retrieval_num} = {recall_at_k}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ 1000 = 0.8140401\n",
      "Recall @ 200 = 0.1641476\n",
      "Recall @ 50 = 0.0337631\n",
      "Recall @ 10 = 0.0149713\n",
      "Recall @ 5 = 0.0093123\n",
      "Recall @ 1 = 0.0022206\n"
     ]
    }
   ],
   "source": [
    "# reranking performance\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates_BM25, 1000)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates_BM25, 200)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates_BM25, 50)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates_BM25, 10)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates_BM25, 5)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates_BM25, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ 1000 = 0.8140401\n",
      "Recall @ 200 = 0.4320081\n",
      "Recall @ 50 = 0.2334408\n",
      "Recall @ 10 = 0.1644102\n",
      "Recall @ 5 = 0.1577483\n",
      "Recall @ 1 = 0.1371896\n"
     ]
    }
   ],
   "source": [
    "# reranking performance\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates, 1000)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates, 200)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates, 50)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates, 10)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates, 5)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates, 1)\n",
    "\n",
    "# margin 20.0\n",
    "# Recall @ 1000 = 0.8085809\n",
    "# Recall @ 200 = 0.3250825\n",
    "# Recall @ 50 = 0.2128713\n",
    "# Recall @ 10 = 0.1683168\n",
    "# Recall @ 5 = 0.1683168\n",
    "# Recall @ 1 = 0.1485149\n",
    "\n",
    "# margin 1.0\n",
    "# Recall @ 1000 = 0.8085809\n",
    "# Recall @ 200 = 0.2706271\n",
    "# Recall @ 50 = 0.1633663\n",
    "# Recall @ 10 = 0.0693069\n",
    "# Recall @ 5 = 0.0594059\n",
    "# Recall @ 1 = 0.049505\n",
    "\n",
    "# margin 15.0 top 10MM\n",
    "# Recall @ 1000 = 0.8140401\n",
    "# Recall @ 200 = 0.4320081\n",
    "# Recall @ 50 = 0.2334408\n",
    "# Recall @ 10 = 0.1644102\n",
    "# Recall @ 5 = 0.1577483\n",
    "# Recall @ 1 = 0.1371896"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute MRR at k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_MRR_metrics(qids_to_relevant_passageids: Dict[int, List[int]], qids_to_ranked_candidate_passages: Dict[int, List[int]], MaxMRRRank:int = 10, verbose: bool=False):\n",
    "    \"\"\"Compute MRR metric\n",
    "    Args:    \n",
    "    p_qids_to_relevant_passageids (dict): dictionary of query-passage mapping\n",
    "        Dict as read in with load_reference or load_reference_from_stream\n",
    "    p_qids_to_ranked_candidate_passages (dict): dictionary of query-passage candidates\n",
    "    Returns:\n",
    "        dict: dictionary of metrics {'MRR': <MRR Score>}\n",
    "    \"\"\"\n",
    "    all_scores = {}\n",
    "    MRR = 0\n",
    "    qids_with_relevant_passages = 0\n",
    "    ranking = []\n",
    "    for qid in qids_to_ranked_candidate_passages:\n",
    "        if qid in qids_to_relevant_passageids:\n",
    "            ranking.append(0)\n",
    "            target_pid = qids_to_relevant_passageids[qid]\n",
    "            candidate_pid = qids_to_ranked_candidate_passages[qid]\n",
    "            if len(candidate_pid) < MaxMRRRank and verbose:\n",
    "                print(f\"warning: candidate pid length {len(candidate_pid)} of qid {qid} is smaller than max MRR rank {MaxMRRRank}\")\n",
    "            for i in range(0, min(MaxMRRRank, len(candidate_pid))):\n",
    "                if candidate_pid[i] in target_pid:\n",
    "                    MRR += 1/(i + 1)\n",
    "                    ranking.pop()\n",
    "                    ranking.append(i+1)\n",
    "                    break\n",
    "    if len(ranking) == 0:\n",
    "        raise IOError(\"No matching QIDs found. Are you sure you are scoring the evaluation set?\")\n",
    "    \n",
    "    # average over all queries\n",
    "    MRR = MRR/len(qids_to_relevant_passageids)\n",
    "    all_scores[f'MRR @ {MaxMRRRank}'] = MRR\n",
    "    all_scores['QueriesRanked'] = len(qids_to_ranked_candidate_passages)\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MRR @ 10': 0.1519798631009233, 'QueriesRanked': 6980} 10\n"
     ]
    }
   ],
   "source": [
    "print(compute_MRR_metrics(query_2_top_pid_groundtruth, query_2_top_pid_candiates), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_file = \"/home/ubuntu/MLData/work/Repos/NeuralIR/results/MSMARCO-psg/retrieve.py/2022-03-18_22.42.10/ranking.tsv\"\n",
    "query_2_pid_raw = collections.defaultdict(list)\n",
    "with open(ranking_file) as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split()\n",
    "        query_2_pid_raw[int(parts[0])].append((int(parts[2]), int(parts[1])))\n",
    "\n",
    "query_2_top_pid_candiates = {}\n",
    "for key in query_2_pid_raw:\n",
    "    query_2_pid_raw[key].sort()\n",
    "    query_2_top_pid_candiates[key] = [e[1] for e in query_2_pid_raw[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ 1000 = 0.965\n",
      "Recall @ 200 = 0.921\n",
      "Recall @ 50 = 0.827\n",
      "Recall @ 10 = 0.634\n",
      "Recall @ 5 = 0.521\n",
      "Recall @ 1 = 0.231\n"
     ]
    }
   ],
   "source": [
    "# retrieval performance\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates, 1000)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates, 200)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates, 50)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates, 10)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates, 5)\n",
    "compute_recall_at_k(query_2_top_pid_groundtruth, query_2_top_pid_candiates, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MRR @ 10': 0.36122180151907973, 'QueriesRanked': 6980} 10\n"
     ]
    }
   ],
   "source": [
    "print(compute_MRR_metrics(query_2_top_pid_groundtruth, query_2_top_pid_candiates), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-depth analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('pytorch_latest_wsl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6391dba84d87d4dbb04f1a2a4c4f01a9e654f64322ed46c975caa8ac3c5b900"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
