# neural_IR

This repository contains a PyTorch framework for training neural based information retrieval applications.

### Dependencies
```
pip install -r requirements.txt
```

## Understand MS MARCO passage ranking data

Full dataset: https://microsoft.github.io/msmarco/Datasets

### Query dataset

Queries for training, development, and evaluation can be downloaded from https://msmarco.blob.core.windows.net/msmarcoranking/queries.tar.gz

Unzip **queries.tar.gz** will produce **queries.dev.tsv**, **queries.eval.tsv**, **queries.train.tsv**

Sample lines in queries.eval.tsv: \
786450  what is presentation software? \
524308  treasury routing number \
33       game called poem who wrote what occasion \
524324  treating hives caused by essential oil \
786472  what is president trump's twitter name \
1048617 who plays steve mcgarrett \
524330  treating post nasal drip cough \
1048619 who plays stitch \

query set | query count
--- | ---
queries.train | 808731
queries.dev | 101093
queries.eval | 101092
queries.dev.small | 6980

queries.dev.small is not directly coming from the original dataset. It is a subset of queries.dev and it has the top1000 BM25 first retrieval results provided the original author. This can be used to perform rerank evaluation.

### Passage corpus

https://msmarco.blob.core.windows.net/msmarcoranking/collection.tar.gz

Unzip **collection.tar.gz** will produce **collection.tsv**

There are **8,841,823** passages in total. Example passages are:\
0       The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated. \
1       The Manhattan Project and its atomic bomb helped bring an end to World War II. Its legacy of peaceful uses of atomic energy continues to have an impact on history and science. \
2       Essay on The Manhattan Project - The Manhattan Project The Manhattan Project was to see if making an atomic bomb possible. The success of this project would forever change the world forever making it known that something this powerful can be manmade.

### Query, Passage relevance label data

Training partition can be downloaded from https://msmarco.blob.core.windows.net/msmarcoranking/qrels.train.tsv
Dev partition can be downloaded from https://msmarco.blob.core.windows.net/msmarcoranking/qrels.dev.tsv

data file | query count | records
--- | --- | ---
qrels.train.tsv | 502939 | 532761
qrels.dev.tsv | 55578 | 59273


Most queries only have one passage being identified as positive passage. Note that: \
    - The set of queries in the qrels.dev.tsv file is only a subset of queries.dev.tsv (59273 vs. 101093)
    - The set of queries in the qrels.train.tsv file is only a subset of queries.train.tsv (502939 vs. 808731)


### triplet training data

Triplet training data in the format of qid, pos_pid, neg_pid can be downloaded from https://msmarco.blob.core.windows.net/msmarcoranking/qidpidtriples.train.full.2.tsv.gz

data file | (distinct) query count | (distinct) passage count | records
--- | --- | --- | ---
qidpidtriples.train.full.2.tsv | 400,782 | 8,829,047 | 397,768,673
qidpidtriples.train.tiny.2.tsv | 400 | 361,629 | 402,026
qidpidtriples.train.small.2.tsv | 4,000 | 2,645,096 |3,978,527
qidpidtriples.train.medium.2.tsv | 12,000 | 5,247,526 | 11,988,093
qidpidtriples.train.large.2.tsv | 40,000 | x | 39,811,288
qidpidtriples.train.small_mixed.2.tsv | 391,202 | 3,002,423 | 3,977,687
qidpidtriples.train.medium_mixed.2.tsv | 395,465 | 5,464,050 | 11,933,060

Note that queries in qidpidtriples.train.full.2.tsv is a subset of queries in queries.train.tsv (400782 vs. 502939)
qidpidtriples.train.tiny.2.tsv is generated by using a query subset (400 queries) from the full query set in qidpidtriples.train.full.2.tsv
qidpidtriples.train.small.2.tsv, qidpidtriples.train.large.2.tsv are generated in a similar fashion.

Note that the negative passage of each query is considered as a hard negative rather than random negative since they are coming the BM25 retrieval results.

### reranking evaluation dataset

Re-ranking takes top 1000 candidates from BM25 as the input.

The original top 1000 candidates for the development set can be downloaded from https://msmarco.blob.core.windows.net/msmarcoranking/top1000.dev.tar.gz

data file | (distinct) query count | records
--- | --- | ---
top1000.dev | 6980 | 6668967

All 6980 queries form a subset of qrels.dev.tsv. Most queries have 1000 passages; some have fewer than 1000 passages.

top1000.eval is a blind, held-out evaluation set with about 6.8 thousand queries is also available and the result is provided by the organizers

## Experiment steps for MS MARCO ranking task

### Data preparation

1) Download from https://microsoft.github.io/msmarco/Datasets

2) Prepare triplet training data for cross encoder 
```
python data_helper/msmarco/build_passage_triplet_crossencoder_train_data.py \
--triplet_file /mnt/d/MLData/data/msmarco_passage/triplets/qidpidtriples.train.medium_mixed.2.tsv \
--passage_collection /mnt/d/MLData/data/msmarco_passage/collection.tsv \
--query_collection /mnt/d/MLData/data/msmarco_passage/queries.train.tsv \
--output_dir ./experiments/msmarco_psg_ranking/cross_encoder_triplet_train_data_medium_mixed
```

```
python data_helper/msmarco/build_passage_triplet_crossencoder_train_data.py \
--triplet_file /mnt/d/MLData/data/msmarco_passage/triplets/qidpidtriples.train.large.2.tsv \
--passage_collection /mnt/d/MLData/data/msmarco_passage/collection.tsv \
--query_collection /mnt/d/MLData/data/msmarco_passage/queries.train.tsv \
--output_dir ./experiments/msmarco_psg_ranking/cross_encoder_triplet_train_data_large
```


2) Prepare triplet training data
```
python data_helper/msmarco/build_passage_triplet_train_data.py \
--tokenizer_name distilbert-base-uncased \
--triplet_file /mnt/d/MLData/data/msmarco_passage/triplets/qidpidtriples.train.tiny.2.tsv \
--passage_collection /mnt/d/MLData/data/msmarco_passage/collection.tsv \
--query_collection /mnt/d/MLData/data/msmarco_passage/queries.train.tsv \
--truncate 128 \
--output_dir ./experiments/msmarco_psg_ranking/triplet_train_data_tiny
```
This will produce two pickle files
experiments/msmarco_psg_ranking/triplet_train_data_tiny/qid_2_query_token_ids.pkl
experiments/msmarco_psg_ranking/triplet_train_data_tiny/pid_2_passage_token_ids.pkl

3) Prepare dev data for validation purpose during the training
```
python build_passage_ranking_dev_data.py \
--tokenizer_name distilbert-base-uncased \
--query_collection /home/ubuntu/MLData/work/Repos/NeuralIR/data/collectionandqueries/queries.dev.small.tsv \
--truncate 128 \
--output_dir /home/ubuntu/MLData/work/Repos/NeuralIR/neural_IR/experiments/msmarco_psg/dev_data
```

### Model training and visualization

We use pytorch-lightning to support distributed model training and monitoring.

```
data_root=./experiments/msmarco_psg_ranking/triplet_train_data_tiny/
export CUDA_VISIBLE_DEVICES="0"
python run_task.py \
--gpus 1 \
--limit_train_batches 1.0 \
--max_epochs 30 \
--lr 1e-6 \
--batch_size 64 \
--margin 15.0 \
--tokenizer_name distilbert-base-uncased \
--pretrained_model_name distilbert-base-uncased \
--model_name bert_encoder \
--loss_name triplet_loss \
--triplet_path ${data_root}triplets.pkl \
--pid_2_passage_token_ids_path ${data_root}pid_2_passage_token_ids.pkl \
--qid_2_query_token_ids_path ${data_root}qid_2_query_token_ids.pkl \
--max_len 128 \
--default_root_dir /home/ubuntu/MLData/work/Repos/NeuralIR/neural_IR/experiments
```

Or you can run script:
> sh tasks/ranking/training/run_task.sh

Visualization using Tensorboard

> tensorboard --logdir mylogdir

### Re-rank 


```

python run_reranking.py \
--qid_2_query_token_ids_path /home/ubuntu/MLData/work/Repos/NeuralIR/neural_IR/experiments/msmarco_psg/dev_data/qid_2_query_token_ids.pkl \
--pid_2_passage_token_ids_path /home/ubuntu/MLData/work/Repos/NeuralIR/neural_IR/experiments/msmarco_psg/train_data_full/pid_2_passage_token_ids.pkl \
--re_rank_input_file_path /home/ubuntu/MLData/work/Repos/NeuralIR/neural_IR/assets/msmarco/query_2_top_1000_passage_BM25.json \
--tokenizer_name distilbert-base-uncased \
--pretrained_model_name distilbert-base-uncased \
--model_checkpoint /home/ubuntu/MLData/work/Repos/NeuralIR/neural_IR/experiments/lightning_logs/version_12/checkpoints/epoch=1-step=312499.ckpt \
--model_name bert_encoder \
--loss_name triplet_loss \
--output_file ranking.tsv
```

### End-to-end retrieval

To enable efficient end-to-end dense retrieval, we can precompute and index passage embeddings offline. 






We use IVFPQ indexing strategy from FAISS. The pre-computation and indexing can be executed via the following

```
python run_retrieval_indexing.py \
--pid_2_passage_token_ids_path /home/ubuntu/MLData/work/Repos/NeuralIR/neural_IR/experiments/msmarco_psg/train_data_full/pid_2_passage_token_ids.pkl \
--tokenizer_name distilbert-base-uncased \
--pretrained_model_name distilbert-base-uncased \
--embedding_save_path passage_embedding.pkl \
--model_checkpoint /home/ubuntu/MLData/work/Repos/NeuralIR/neural_IR/experiments/lightning_logs/version_14/checkpoints/epoch=0-step=156249.ckpt \
--num_partitions 2000 \
--subquantizer_number 8 \
--subquantizer_codebook_size 8 \
--model_name bert_encoder \
--loss_name triplet_loss \
--index_save_path embed.index
```

Given a list of query, the end-to-end retrieval of relevant passages from the 8.8M passages can be run via

```
python run_retrieval.py \
--qid_2_query_token_ids_path /home/ubuntu/MLData/work/Repos/NeuralIR/neural_IR/experiments/msmarco_psg/dev_data/qid_2_query_token_ids.pkl \
--pid_2_embedding_path /home/ubuntu/MLData/work/Repos/NeuralIR/neural_IR/passage_embedding.pkl \
--tokenizer_name distilbert-base-uncased \
--pretrained_model_name distilbert-base-uncased \
--model_checkpoint /home/ubuntu/MLData/work/Repos/NeuralIR/neural_IR/experiments/lightning_logs/version_12/checkpoints/epoch=1-step=312499.ckpt \
--index_save_path /home/ubuntu/MLData/work/Repos/NeuralIR/neural_IR/embed.index \
--number_nearest_neighbors 5 \
--output_file retrieval.tsv \
--model_name bert_encoder \
--loss_name triplet_loss
```






### Notebooks for analyzing ranking results

notebooks/Result_analysis.ipynb




### Results

| Model  | MRR@10 | Recall@5 | Recall@20 | Recall@1100 |
|--------|--------|----------|-----------|-------------|
| MiniLM | 37.69  | 52.75    | 70.28     | 79.67       |
| Bert-base |        |          |           |             |
|        |        |          |           |             |

